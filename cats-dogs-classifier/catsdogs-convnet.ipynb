{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: FALSE. Running on the cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"CUDA: TRUE. Running on the gpu.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA: FALSE. Running on the cpu\")\n",
    "\n",
    "class DogsVsCats():\n",
    "    IMG_SIZE = 50\n",
    "    CATS = \"C:/Users/Dylan/Desktop/build/python_projects/pytorch_neural_network/convnet_pytorch/PetImages/Cat\"\n",
    "    DOGS = \"C:/Users/Dylan/Desktop/build/python_projects/pytorch_neural_network/convnet_pytorch/PetImages/Dog\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "    \n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                # label is the directory PetImages/Cat\n",
    "                # f is the filename in the directory label\n",
    "                try:\n",
    "                    path = os.path.join(label, f) # PetImages/Cat/ + cat_image_1.png\n",
    "                    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) # read each image in grayscale\n",
    "                    img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE)) # resize img to 50 x 50\n",
    "                    # fill all image tensors to training data set (all cats, then all dogs)\n",
    "                    self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]]) # [[image], [1hot vector]]\n",
    "                    \n",
    "                    if label == self.CATS:\n",
    "                        self.catcount += 1\n",
    "                    elif label == self.DOGS:\n",
    "                        self.dogcount += 1\n",
    "                except Exception as e:\n",
    "                    # image being loaded (processed) is invalid\n",
    "                    pass\n",
    "                    print(str(e))\n",
    "\n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print(\"Cats: \", self.catcount)\n",
    "        print(\"Dogs: \", self.dogcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running with already built training data.\n"
     ]
    }
   ],
   "source": [
    "REBUILD_DATA = False\n",
    "\n",
    "# Pre-process all images data into grayscale, count all image types and build training_data list\n",
    "if REBUILD_DATA:\n",
    "    dogsvscats = DogsVsCats()\n",
    "    dogsvscats.make_training_data()\n",
    "    print(\"rebuilding training data.\")\n",
    "else:\n",
    "    print(\"running with already built training data.\")\n",
    "    \n",
    "training_data = np.load(\"training_data.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                        | 0/674 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 674/674 [03:42<00:00,  3.03it/s]\n",
      "  0%|▍                                                                                            | 35/7483 [00:00<00:21, 339.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1771, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 7483/7483 [00:18<00:00, 401.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# plt.imshow(training_data[12][0], cmap = \"gray\") # training_data[] <- index of which file, [] <- index of image/label. [0] = image, [1] = label\n",
    "# plt.show()\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # init the nn.Module include\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # 5 kernel size (5x5 window)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "        x = torch.randn(50, 50).view(-1, 1, 50, 50) # 50 x 50 images for input\n",
    "        self._to_linear = None\n",
    "        # Convs runs the first 3 convolutional layers to determine the data size, then we can use the linear (dense) layers\n",
    "        # with a definitive output size.\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "\n",
    "    # Convolutional layers to initialize convolutional data tensor size with random data\n",
    "    def convs(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "        # by now, x is the final output tensor from the conv layers.\n",
    "\n",
    "        #print(x[0].shape)\n",
    "        # Determine the needed tensor dimension for the fc1 layer input.\n",
    "        if self._to_linear is None: # First initialization\n",
    "            self._to_linear = x[0].shape[0] * x[0].shape[1] * x[0].shape[2] # 5 x 3 x 10 tensor\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear) # Flatten the input data (x) after its been passed through conv layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim = 1)\n",
    "\n",
    "net = Net()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "X = torch.Tensor([i[0] for i in training_data]).view(-1, 50, 50) # X is the tensor of 50 x 50 image pixels.\n",
    "X = X / 255 # Scale 0-255 values between 0-1\n",
    "y = torch.Tensor([i[1] for i in training_data]) # y is the tensor of labels [cat, dog]\n",
    "\n",
    "VAL_PCT = 0.1\n",
    "val_size = int(len(X) * VAL_PCT)\n",
    "print(val_size)\n",
    "\n",
    "train_X = X[:-val_size] # take front of list to -val_size (start at end, move back to val_size) (front majority of list)\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_X = X[-val_size:] # -val_size (backward from end to val_size) onward (end portion of the list)\n",
    "test_y = y[-val_size:]\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 1\n",
    "\n",
    "TRAIN_MODEL = True\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    for epoc in range(EPOCHS):\n",
    "        for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
    "            batch_X = train_X[i:i + BATCH_SIZE].view(-1, 1, 50, 50) # batch of 100 image pixel tensors\n",
    "            batch_y = train_y[i:i + BATCH_SIZE] # batch of 100 labels\n",
    "\n",
    "            # Begin fitment of model using each batch, backpropagate and adjust weights.\n",
    "            # Need to zero the gradients in each backpropagation\n",
    "            net.zero_grad()\n",
    "            outputs = net(batch_X) # feedforward, gives forward end output\n",
    "            loss = loss_function(outputs, batch_y) # loss(input, target) -> Value to be tested, correct target loss is determined from.\n",
    "            loss.backward() # calculate loss on each weight\n",
    "            optimizer.step() # adjust each weight\n",
    "\n",
    "    print(loss)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_X))):\n",
    "        real_class = torch.argmax(test_y[i])\n",
    "        net_out = net(test_X[i].view(-1, 1, 50, 50))[0] # 1 hot vector, 2 values (dog or cat)\n",
    "        predicted_class = torch.argmax(net_out) # dog or cat\n",
    "        if predicted_class == real_class:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct / total, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"comma-speed-challenge.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPhDGdfxNXzoFSONG/Bgpnn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"yoY0FkQ-hLPJ","executionInfo":{"status":"ok","timestamp":1601777433409,"user_tz":240,"elapsed":278,"user":{"displayName":"e e","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRFShoYRsDhZnpGvDhrdiTr-lcKIMYOM41EgrP=s64","userId":"09974983085928519513"}},"outputId":"1bb80fbd-6406-4c5c-8acb-abbcd5133fcc","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","from google.colab import files\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aRPOdhQRiEb0","executionInfo":{"status":"ok","timestamp":1601777525045,"user_tz":240,"elapsed":1855,"user":{"displayName":"e e","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRFShoYRsDhZnpGvDhrdiTr-lcKIMYOM41EgrP=s64","userId":"09974983085928519513"}},"outputId":"d9773e47-6861-4e83-a59f-f01672afeb4e","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["data_path='/content/drive/My Drive/Colab/comma/comma-speed-challenge/data/'\n","root_path='/content/drive/My Drive/Colab'\n","\n","def prep_data():\n","\n","  # RAM ISSUE.\n","  # need to load all data, convert sequential to optical flow images and zip with speeds\n","  # then shuffle this optical flow data\n","  # then make batches out of it.\n","\n","  data_file = \"training_small.npy\"\n","  full_data = np.load(data_path+data_file, allow_pickle=True) # small training data file data[0] == img, data[1] = label\n","  # full_data = full_data[:-int(len(full_data)*(3/4))] #h1\n","\n","  training_data, validation_data = train_val_split(full_data, val_size=VAL_SIZE)\n","\n","  train_batch_data = list(make_batches(training_data, BATCH_SIZE, shuffle=True))\n","  print(f\"Finished loading {len(train_batch_data)} batches (b={BATCH_SIZE}) of training samples.\")\n","\n","  validation_batch_data = list(make_batches(validation_data, BATCH_SIZE, shuffle=False))\n","  print(f\"Finished loading {len(validation_batch_data)} batches (b={BATCH_SIZE}) of validation samples.\")\n","\n","  return train_batch_data, validation_batch_data\n","\n","train_batch_data, validation_batch_data = prep_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training data length: 25 frames.\n","validation data length:  6 frames.\n","Finished loading 1 batches (b=32) of training samples.\n","Finished loading 0 batches (b=32) of validation samples.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SfsbiEoqPpI2","executionInfo":{"status":"ok","timestamp":1601777827706,"user_tz":240,"elapsed":3958,"user":{"displayName":"e e","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRFShoYRsDhZnpGvDhrdiTr-lcKIMYOM41EgrP=s64","userId":"09974983085928519513"}},"outputId":"16350043-457e-4fe0-f4df-1b64d182e88c","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#!/usr/bin/env python\n","\n","import os\n","import time\n","import torch\n","import torchvision\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision import datasets, transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import copy\n","\n","import cv2\n","import numpy as np\n","import random\n","from random import randint\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","learning_rate = 0.001\n","\n","VAL_SIZE = 0.2\n","EPOCHS = 55\n","BATCH_SIZE = 32\n","INPUT_CHANNELS = 3\n","IMG_SIZE = (200, 66)\n","\n","# tensorboard\n","log_dir = \"./logs\"\n","writer = SummaryWriter(log_dir)\n","\n","def train_val_split(data, val_size):\n","\n","\tval_size = int(len(data) * val_size)\n","\n","\ttraining_data = data[:-val_size]\n","\tvalidation_data = data[-val_size:]\n","\n","\tprint(f\"Training data length: {len(training_data)} frames.\")\n","\tprint(f\"validation data length:  {len(validation_data)} frames.\")\n","\n","\treturn training_data, validation_data\n","\n","def augment_brightness(img, brightness_factor):\n","\t# augment an rgb image with a specified brightness factor, cvt back to rgb and return img as np.array.\n","\thsv_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","\thsv_image[:, :, 2] = hsv_image[:, :, 2] * brightness_factor\n","\timg = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2BGR)\n","\treturn img\n","\n","def opticalflow(img1, img2): # DOF\n","\t\n","\thsv = np.zeros_like(img1)\n","\thsv[...,1] = 255\n","\n","\tgray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n","\tgray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n","\n","\t# flow_data = cv2.calcOpticalFlowFarneback(prev, nxt, None, 0.4, 1, 12, 2, 8, 1.2, 0)\n","\tflow = cv2.calcOpticalFlowFarneback(gray1, gray2, flow=None, pyr_scale=0.5, \n","                                        levels=3, winsize=15, iterations=3, \n","                                        poly_n=5, poly_sigma=1.2, flags=0)\n","\n","\tmag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n","\n","\thsv[:,:,0] = ang*(180/np.pi/2)\n","\thsv[:,:,2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n","\t# hsv[...,2] = (mag * 15).astype(int)\n","\t\n","\trgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n","\n","\t# plt.imshow(rgb)\n","\t# plt.show()\n","\n","\treturn rgb\n","\n","# opticalflow(train_data[0][0], train_data[1][0])\n","\n","def make_batches(data, batch_size, shuffle):\n","\n","\t# data fed into this is sequential and unshuffled video driving data.\n","\t# once flow images are calculated they (can) be shuffled\n","\n","\tx_data = []\n","\ty_data = []\n","\n","\tdata_both = []\n","\n","\tflow_data = []\n","\tspeed_data = []\n","\n","\timg_channels = 3 # img channels for making flow images with cv2 input is 3 to keep hsv.\n","\t\t\t\t\t# INPUT_CHANNELS = 2 -> hsv images are converted to 2-channel np arrays to input for network.\n","\n","\t# generate all dense optical flow images from data images and their associated labels\n","\tfor i in range(0, len(data)-1, 1):\n","\t\t# 2 imgs per step = 32 images for batch=32.\n","\t\timg1 = data[i][0]\n","\t\t# print(i)\n","\t\timg2 = data[i+1][0]\n","\t\t\n","\t\t# preprocessing images to optimize generalization\n","\t\tbrightness_factor = np.random.uniform() + 0.7\n","\t\timg1 = augment_brightness(img1, brightness_factor)\n","\t\timg2 = augment_brightness(img2, brightness_factor)\n","\n","\t\t# plt.imshow(img2)\n","\t\t# plt.show()\n","\n","\t\tflow_img = opticalflow(img1, img2)\n","\t\tflow_img = cv2.resize(flow_img, (IMG_SIZE[0], IMG_SIZE[1]), interpolation=cv2.INTER_AREA)\n","\t\tflow_img = flow_img / 127.5 - 1.0\n","\t\t\n","\t\t# flip image and make another flow image\n","\t\timg1_flip = np.flip(img1, 1)\n","\t\timg2_flip = np.flip(img2, 1)\n","\t\tflow_img_flip = opticalflow(img1_flip, img2_flip)\n","\t\tflow_img_flip = cv2.resize(flow_img_flip, (IMG_SIZE[0], IMG_SIZE[1]), interpolation=cv2.INTER_AREA)\n","\t\tflow_img_flip = flow_img_flip / 127.5 - 1.0\n","\n","\t\tspeed1 = data[i][1]\n","\t\tspeed2 = data[i+1][1]\n","\t\tmean_speed = [np.mean([speed1, speed2])]\n","\n","\t\t# put [flow img, label] in an array, shuffle this array.\n","\t\tdata_both.append([flow_img, mean_speed])\n","\t\tdata_both.append([flow_img_flip, mean_speed])\n","\n","\tif shuffle:\n","\t\trandom.shuffle(data_both)\n","\tfor i in range(len(data_both)):\n","\t\t# make parallel arrays of flow imgs, label.\n","\t\tflow_data.append(data_both[i][0])\n","\t\tspeed_data.append(data_both[i][1])\n","\n","\t# sort all DOF data into batches=32\n","\timage_batch = np.empty((batch_size, IMG_SIZE[1], IMG_SIZE[0], img_channels), dtype=\"float64\")\n","\tlabel_batch = np.empty((batch_size, 1))\n","\n","\tidx = 0\n","\tfor j in range(len(flow_data)):\n","\t\tif idx % batch_size == 0 and idx != 0:\n","\t\t\t# finished a batch\n","\t\t\timg_batch = image_batch\n","\t\t\t# img_batch = img_batch[:,:,:,[0,2]] # extract hue and value channels with flow data\n","\t\t\timg_batch = np.reshape(img_batch, (batch_size, INPUT_CHANNELS, IMG_SIZE[0], IMG_SIZE[1]))\n","\t\t\tx_data.append(copy.deepcopy(torch.from_numpy(img_batch)))\n","\t\t\ty_data.append(copy.deepcopy(torch.DoubleTensor(label_batch)))\n","\t\t\tidx = 0\n","\n","\t\timage_batch[idx] = flow_data[j]\t\t\t# idx loops 0-31, makes batches of 32.\n","\t\tlabel_batch[idx] = speed_data[j]\t\t# j loops len of flow_data\n","\t\tidx += 1\n","\n","\t# x_data = array of 32-batch image tensors, [0] is a batch, [1] is a batch, etc.\n","\t# y_data = array of 32-batch labels\n","\treturn zip(x_data, y_data)\n","\n","class SNet(nn.Module):\n","\tdef __init__(self):\n","\t\tsuper().__init__()\n","\t\tself.conv1 = nn.Conv2d(in_channels=INPUT_CHANNELS, out_channels=24, kernel_size=5, stride=2)\n","\t\tself.conv2 = nn.Conv2d(in_channels=24, out_channels=36, kernel_size=5, stride=2)\n","\t\tself.conv3 = nn.Conv2d(in_channels=36, out_channels=48, kernel_size=5, stride=2)\n","\t\tself.conv3_drop = nn.Dropout2d(p=0.5)\n","\t\tself.conv4 = nn.Conv2d(in_channels=48, out_channels=64, kernel_size=3)\n","\t\tself.conv5 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n","\t\tself.conv_flatten = nn.Flatten()\n","\n","\t\tself.fc1 = nn.Linear(in_features=1152, out_features=100)\n","\t\tself.fc2 = nn.Linear(in_features=100, out_features=50)\n","\t\t# self.fc2_drop = nn.Dropout2d(p=0.5)\n","\t\tself.fc3 = nn.Linear(in_features=50, out_features=10)\n","\t\tself.fc4 = nn.Linear(in_features=10, out_features=1)\n","\n","\t# tests:\n","\t\t# - remove dropout from conv layer\n","\t\t# - decrease parameters in dense layers with dropouts to prevent overfit\n","\t\t# 5 conv layers, 2 dense\n","\n","\t# next to do\n","\t\t# - 5 conv nets, 3 dense nets, \n","\n","\tdef forward(self, x):\n","\t\tx = F.relu(self.conv1(x))\n","\t\tx = F.relu(self.conv2(x))\n","\t\tx = F.relu(self.conv3(x))\n","\t\tx = self.conv3_drop(x)\n","\t\tx = F.relu(self.conv4(x))\n","\t\tx = F.relu(self.conv5(x))\n","\t\tx = self.conv_flatten(x)\n","\n","\t\t# x = x.view(-1, x[0].shape[0]*x[0].shape[1]*x[0].shape[2]) # reshape to 128, in features of first nn.Linear layer.\n","\t\tx = F.relu(self.fc1(x))\n","\t\tx = F.relu(self.fc2(x))\n","\t\t# x = self.fc2_drop(x)\n","\t\tx = F.relu(self.fc3(x)) # no activation function\n","\t\tx = self.fc4(x)\n","\t\treturn x\n","\n","# def prep_data():\n","#   data_file = \"training_full_quarter4.npy\"\n","#   full_data = np.load(data_path+data_file, allow_pickle=True) # small training data file data[0] == img, data[1] = label\n","\n","#   training_data, validation_data = train_val_split(full_data, val_size=VAL_SIZE)\n","\n","#   train_batch_data = list(make_batches(training_data, BATCH_SIZE, shuffle=True))\n","#   print(f\"Finished loading {len(train_batch_data)} batches (b={BATCH_SIZE}) of training samples.\")\n","\n","#   validation_batch_data = list(make_batches(validation_data, BATCH_SIZE, shuffle=False))\n","#   print(f\"Finished loading {len(validation_batch_data)} batches (b={BATCH_SIZE}) of validation samples.\")\n","\n","#   return train_batch_data, validation_batch_data\n","\n","# train_batch_data, validation_batch_data = prep_data()\n","\n","# TRAINING\n","def train_model(train_batch_data, validation_batch_data):\n","\ttrain_start_time = time.time()\n","\n","\ttotal_steps = 0\n","\ttotal_accuracy = 0\n","\ttotal_loss = 0\n","\tval_loss = 0\n","\n","\tprev_mean_epoch_val_loss = 0\n","\tval_epoch_streak = 0\n","\n","\t# model = torch.load(\"MODEL-(=70e)-DOF-[full].pth\")\n","\tmodel = net\n","\toptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","\tnum_steps_print = 1\n","\tnum_steps_test = 25\n","\n","\tfor epoch in tqdm(range(EPOCHS)):\n","\n","\t\trunning_loss = 0.0\n","\t\tepoch_val_running_loss = 0\n","\t\tnum_validation_tests = 1\n","\n","\t\tfor i in tqdm(range(0, len(train_batch_data), 1)): # loop over each batch, begin at 0: i = idx, data = data[img, label]\n","\t\t\ttotal_steps += 1\n","\n","\t\t\tdata = train_batch_data[i]\n","\n","\t\t\tb_imgs, b_labels = data\n","\t\t\tb_imgs, b_labels = b_imgs.to(device), b_labels.to(device)\n","\n","\t\t\toutputs = model(b_imgs)\n","\t\t\t# outputs are ([1, 32]) == labels ([1, 32]) for loss function.\n","\n","\t\t\taccuracy = torch.mean( outputs / b_labels ).item() # every batch\n","\t\t\ttotal_accuracy += torch.mean( outputs / b_labels ).item() # entirety of training\n","\n","\t\t\tloss = loss_function(outputs, b_labels)\n","\t\t\tloss.backward()\n","\t\t\toptimizer.step()\n","\t\t\toptimizer.zero_grad()\n","\t \n","\t\t\trunning_loss += loss.item()\n","\t\t\ttotal_loss += loss.item()\n","\n","\t\t\t# test on validation data\n","\t\t\tif i % num_steps_test == num_steps_test-1:\n","\t\t\t\tidx = randint(0, len(validation_batch_data) - 1)\n","\t\t\t\ttest_x, test_y = validation_batch_data[idx] # [0] == imgs\n","\t\t\t\ttest_x, test_y = test_x.to(device), test_y.to(device)\n","\t\t\t\tval_outputs = model(test_x)\n","\t\t\t\tval_loss = loss_function(val_outputs, test_y).item()\t\n","\t\t\t\tval_accuracy = torch.mean(val_outputs / test_y).item()\n","\t\t\n","\t\t\t\tepoch_val_running_loss += val_loss\n","\t\t\t\tnum_validation_tests += 1\n","\n","\t\t\t\t# tensorboard log validation\n","\t\t\t\twriter.add_scalar('Loss/validation', val_loss, (i+1)*(epoch+1))\n","\t\t\t\twriter.add_scalar('Accuracy/validation', val_accuracy, (i+1)*(epoch+1))\n","\t\t\t\tprint(f\"[{epoch + 1}/{EPOCHS},   {i + 1}/{len(train_batch_data)}], [VALIDATION]: x = {round(val_outputs[0].item(), 3)} y = {round(test_y[0].item(), 3)}, accuracy: {val_accuracy}, loss: {val_loss}\")\n","\n","\t\t\tif i % num_steps_print == num_steps_print-1: # print update every 10 steps\n","\t\t\t\tprint(f\"[e={epoch + 1},   b={i + 1}/{len(train_batch_data)}]: x = {round(outputs[0].item(), 3)} y = {round(b_labels[0].item(), 3)}, accuracy: {accuracy}, loss: {running_loss/num_steps_print}\")\n","\t\t\t\twriter.add_scalar('Loss/train', running_loss/num_steps_print, (i+1)*(epoch+1))\n","\t\t\t\twriter.add_scalar('Accuracy/train', accuracy, (i+1)*(epoch+1))\n","\t\t\t\trunning_loss = 0\n","\n","\t\t# end each epoch, check if mean validation loss is higher that last epoch, if so, stop training to stop overfit.\n","\t\tif num_validation_tests > 1:\n","\t\t\tnum_validation_tests -= 1\n","\t\tmean_epoch_val_loss = epoch_val_running_loss / num_validation_tests\n","\t\tif mean_epoch_val_loss > prev_mean_epoch_val_loss and prev_mean_epoch_val_loss != 0: # validation loss increased this epoch\n","\t\t\tval_epoch_streak += 1\n","\t\t\tif val_epoch_streak >= 2:\n","\t\t\t\tprint(\"Validation loss higher than previous epoch. Stopping training to prevent overfitting.\")\n","\t\t\t\tbreak\n","\t\telse:\n","\t\t\t# val mse decreased for an epoch, reset streak.\n","\t\t\tval_epoch_streak = 0\n","\n","\t\tprev_mean_epoch_val_loss = mean_epoch_val_loss # set new previous val loss\n","\n","\t# finished epochs\n","\ttrain_time = time.time() - train_start_time\n","\ttorch.save(model, f\"MODEL-(={EPOCHS}e)-DOF-[good-testing].pth\")\n","\tprint(f\"Finished training model: epochs: {EPOCHS}. train time: {round(train_time, 4)} sec ({round(train_time/60, 4)} min.). total accuracy: {round((total_accuracy/total_steps),4)}, MSE loss: {round((total_loss/total_steps),4)}. Saved model.\")\n","\n","if __name__ == \"__main__\":\n","\t\n","\tif torch.cuda.is_available():\n","\t\tprint(\"CUDA: True. Running on the GPU.\")\n","\telse:\n","\t\tprint(\"CUDA: False. Slow on the CPU.\")\n","\tdevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","\tnet = SNet().to(device)\n","\tnet = net.double()\n","\tloss_function = nn.MSELoss()\n","\toptimizer = optim.Adam(net.parameters(), lr=learning_rate)\n","\n","\ttrain_model(train_batch_data, validation_batch_data)\n","\t# test_model(video_file=\"data/test.mp4\", model=\"MODEL-(=50e)-DOF-[2chan].pth\")\n","\n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 0/55 [00:00<?, ?it/s]\n","  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n","100%|██████████| 1/1 [00:00<00:00,  8.94it/s]\n","  2%|▏         | 1/55 [00:00<00:06,  8.47it/s]\n","  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["CUDA: True. Running on the GPU.\n","[e=1,   b=1/1]: x = 0.096 y = 27.999, accuracy: 0.003437749829022758, loss: 777.0291684348671\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 1/1 [00:00<00:00,  9.26it/s]\n","  4%|▎         | 2/55 [00:00<00:06,  8.60it/s]\n","100%|██████████| 1/1 [00:00<00:00, 19.52it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 20.06it/s]\n","  7%|▋         | 4/55 [00:00<00:05, 10.16it/s]\n","100%|██████████| 1/1 [00:00<00:00, 20.32it/s]\n","\n","  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["[e=2,   b=1/1]: x = 0.103 y = 27.999, accuracy: 0.003675249484350599, loss: 776.6589367448353\n","[e=3,   b=1/1]: x = 0.118 y = 27.999, accuracy: 0.004264912550293057, loss: 775.7398566257435\n","[e=4,   b=1/1]: x = 0.15 y = 27.999, accuracy: 0.006206591570905285, loss: 772.7185389779311\n","[e=5,   b=1/1]: x = 0.271 y = 27.999, accuracy: 0.01032683958949604, loss: 766.3282552487798\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 20.70it/s]\n"," 11%|█         | 6/55 [00:00<00:04, 11.78it/s]\n","100%|██████████| 1/1 [00:00<00:00, 21.84it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 21.98it/s]\n"," 15%|█▍        | 8/55 [00:00<00:03, 13.39it/s]\n","100%|██████████| 1/1 [00:00<00:00, 21.93it/s]\n","\n","  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["[e=6,   b=1/1]: x = 0.95 y = 27.999, accuracy: 0.026303864024510126, loss: 741.8115800096782\n","[e=7,   b=1/1]: x = 1.787 y = 27.999, accuracy: 0.06193759211915573, loss: 688.5717662951345\n","[e=8,   b=1/1]: x = 3.802 y = 27.999, accuracy: 0.13300378655067688, loss: 588.6028112238807\n","[e=9,   b=1/1]: x = 5.673 y = 27.999, accuracy: 0.27753552487645394, loss: 410.3910325665572\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 20.97it/s]\n"," 18%|█▊        | 10/55 [00:00<00:03, 14.68it/s]\n","100%|██████████| 1/1 [00:00<00:00, 21.77it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 21.65it/s]\n"," 22%|██▏       | 12/55 [00:00<00:02, 15.92it/s]\n","100%|██████████| 1/1 [00:00<00:00, 21.95it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n","\n","  0%|          | 0/1 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[e=10,   b=1/1]: x = 19.122 y = 27.999, accuracy: 0.5796444496542852, loss: 152.26427938437308\n","[e=11,   b=1/1]: x = 26.38 y = 27.999, accuracy: 1.1531167864130416, loss: 98.51918803550507\n","[e=12,   b=1/1]: x = 56.412 y = 27.999, accuracy: 1.6293220101478108, loss: 407.8804158029295\n","[e=13,   b=1/1]: x = 54.351 y = 27.999, accuracy: 1.281297572818994, loss: 154.5257255850683\n","[e=14,   b=1/1]: x = 27.885 y = 27.999, accuracy: 0.786080379530356, loss: 69.99985791526791\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 21.57it/s]\n"," 27%|██▋       | 15/55 [00:00<00:02, 17.05it/s]\n","100%|██████████| 1/1 [00:00<00:00, 22.52it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 21.54it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 21.61it/s]\n"," 33%|███▎      | 18/55 [00:01<00:02, 18.00it/s]\n","100%|██████████| 1/1 [00:00<00:00, 21.81it/s]\n","\n","  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["[e=15,   b=1/1]: x = 21.331 y = 27.999, accuracy: 0.6393634612971832, loss: 117.18704794803051\n","[e=16,   b=1/1]: x = 15.833 y = 27.999, accuracy: 0.44712541151363794, loss: 245.12936299181112\n","[e=17,   b=1/1]: x = 16.388 y = 27.999, accuracy: 0.4081435446364202, loss: 285.99487376503953\n","[e=18,   b=1/1]: x = 12.973 y = 27.999, accuracy: 0.46223126328037106, loss: 229.98419640003\n","[e=19,   b=1/1]: x = 9.661 y = 27.999, accuracy: 0.46747275593687876, loss: 229.86249942075244\n"],"name":"stdout"},{"output_type":"stream","text":["\r100%|██████████| 1/1 [00:00<00:00, 21.50it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 21.54it/s]\n"," 38%|███▊      | 21/55 [00:01<00:01, 18.62it/s]\n","100%|██████████| 1/1 [00:00<00:00, 21.66it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 21.64it/s]\n"," 42%|████▏     | 23/55 [00:01<00:01, 18.97it/s]\n","  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["[e=20,   b=1/1]: x = 16.977 y = 27.999, accuracy: 0.614167211413349, loss: 138.85352912729613\n","[e=21,   b=1/1]: x = 21.31 y = 27.999, accuracy: 0.7483013812554172, loss: 68.23352931641097\n","[e=22,   b=1/1]: x = 19.446 y = 27.999, accuracy: 0.9854689085920183, loss: 36.182802112820056\n","[e=23,   b=1/1]: x = 26.957 y = 27.999, accuracy: 1.2513796478961103, loss: 117.40398987909921\n"],"name":"stdout"},{"output_type":"stream","text":["\r100%|██████████| 1/1 [00:00<00:00, 21.52it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 21.40it/s]\n"," 45%|████▌     | 25/55 [00:01<00:01, 19.17it/s]\n","100%|██████████| 1/1 [00:00<00:00, 21.49it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 22.02it/s]\n"," 49%|████▉     | 27/55 [00:01<00:01, 19.21it/s]\n","  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["[e=24,   b=1/1]: x = 27.809 y = 27.999, accuracy: 1.2873572845751728, loss: 141.5190328235484\n","[e=25,   b=1/1]: x = 22.185 y = 27.999, accuracy: 1.2166677512042292, loss: 72.0713397865463\n","[e=26,   b=1/1]: x = 24.794 y = 27.999, accuracy: 0.9903619293445013, loss: 48.10040620395306\n","[e=27,   b=1/1]: x = 25.672 y = 27.999, accuracy: 0.858820573840852, loss: 46.33604094721367\n"],"name":"stdout"},{"output_type":"stream","text":["\r100%|██████████| 1/1 [00:00<00:00, 21.71it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 21.91it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 21.60it/s]\n"," 55%|█████▍    | 30/55 [00:01<00:01, 19.53it/s]\n","100%|██████████| 1/1 [00:00<00:00, 22.11it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 21.76it/s]\n","\n"],"name":"stderr"},{"output_type":"stream","text":["[e=28,   b=1/1]: x = 22.64 y = 27.999, accuracy: 0.7644701894690535, loss: 59.25535805528217\n","[e=29,   b=1/1]: x = 17.96 y = 27.999, accuracy: 0.7641442748176359, loss: 63.939625515115786\n","[e=30,   b=1/1]: x = 18.828 y = 27.999, accuracy: 0.6815130705182899, loss: 97.19897199922438\n","[e=31,   b=1/1]: x = 26.77 y = 27.999, accuracy: 0.7527856321540685, loss: 67.66234738134659\n","[e=32,   b=1/1]: x = 30.993 y = 27.999, accuracy: 0.8587807111355388, loss: 37.676863732097964\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 22.08it/s]\n"," 60%|██████    | 33/55 [00:01<00:01, 19.72it/s]\n","100%|██████████| 1/1 [00:00<00:00, 21.84it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 21.83it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 22.99it/s]\n"," 65%|██████▌   | 36/55 [00:01<00:00, 20.04it/s]\n","100%|██████████| 1/1 [00:00<00:00, 21.50it/s]\n","\n","  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["[e=33,   b=1/1]: x = 30.498 y = 27.999, accuracy: 0.9320425646368913, loss: 34.17604866236937\n","[e=34,   b=1/1]: x = 28.371 y = 27.999, accuracy: 1.0571890742499774, loss: 63.03215544106288\n","[e=35,   b=1/1]: x = 25.436 y = 27.999, accuracy: 1.0645375569703903, loss: 59.07993003918794\n","[e=36,   b=1/1]: x = 42.097 y = 27.999, accuracy: 1.1303772516805213, loss: 70.50747798805573\n","[e=37,   b=1/1]: x = 29.371 y = 27.999, accuracy: 1.0551766621016592, loss: 53.49636940470489\n"],"name":"stdout"},{"output_type":"stream","text":["\r100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 21.97it/s]\n"," 71%|███████   | 39/55 [00:02<00:00, 20.17it/s]\n","100%|██████████| 1/1 [00:00<00:00, 22.59it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 22.68it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 20.91it/s]\n"," 76%|███████▋  | 42/55 [00:02<00:00, 20.12it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[e=38,   b=1/1]: x = 26.701 y = 27.999, accuracy: 1.0534763186427565, loss: 33.52899097717031\n","[e=39,   b=1/1]: x = 33.459 y = 27.999, accuracy: 0.953489166002823, loss: 35.06399516974019\n","[e=40,   b=1/1]: x = 28.82 y = 27.999, accuracy: 0.8442747010434246, loss: 40.15847511615836\n","[e=41,   b=1/1]: x = 16.246 y = 27.999, accuracy: 0.7998706349706247, loss: 54.48383093216208\n","[e=42,   b=1/1]: x = 25.124 y = 27.999, accuracy: 0.8106794213574757, loss: 54.73458688231357\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 21.41it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 22.63it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 21.57it/s]\n"," 82%|████████▏ | 45/55 [00:02<00:00, 19.98it/s]\n","100%|██████████| 1/1 [00:00<00:00, 22.68it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 20.81it/s]\n","\n"],"name":"stderr"},{"output_type":"stream","text":["[e=43,   b=1/1]: x = 32.181 y = 27.999, accuracy: 0.8552525375303877, loss: 47.31799709824612\n","[e=44,   b=1/1]: x = 32.973 y = 27.999, accuracy: 0.8911706256906807, loss: 40.927600526402365\n","[e=45,   b=1/1]: x = 24.152 y = 27.999, accuracy: 0.9512472630195312, loss: 36.370860087029385\n","[e=46,   b=1/1]: x = 27.13 y = 27.999, accuracy: 1.014764195648357, loss: 44.4763956097764\n","[e=47,   b=1/1]: x = 31.093 y = 27.999, accuracy: 1.0617896471724078, loss: 75.960929030324\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 21.52it/s]\n"," 87%|████████▋ | 48/55 [00:02<00:00, 19.89it/s]\n","100%|██████████| 1/1 [00:00<00:00, 21.78it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 21.87it/s]\n"," 91%|█████████ | 50/55 [00:02<00:00, 19.71it/s]\n","100%|██████████| 1/1 [00:00<00:00, 21.96it/s]\n","\n","  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["[e=48,   b=1/1]: x = 26.783 y = 27.999, accuracy: 1.0133318378429244, loss: 38.39039024109881\n","[e=49,   b=1/1]: x = 25.552 y = 27.999, accuracy: 0.9917448076085322, loss: 45.10472948652324\n","[e=50,   b=1/1]: x = 30.319 y = 27.999, accuracy: 0.9398596775541466, loss: 25.587156600037954\n","[e=51,   b=1/1]: x = 25.291 y = 27.999, accuracy: 0.9665511909493609, loss: 26.27378901201204\n","[e=52,   b=1/1]: x = 28.7 y = 27.999, accuracy: 0.9006320035040138, loss: 33.90866430496361\n"],"name":"stdout"},{"output_type":"stream","text":["\r100%|██████████| 1/1 [00:00<00:00, 21.66it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 22.56it/s]\n"," 96%|█████████▋| 53/55 [00:02<00:00, 20.04it/s]\n","100%|██████████| 1/1 [00:00<00:00, 21.36it/s]\n","\n","100%|██████████| 1/1 [00:00<00:00, 21.92it/s]\n","100%|██████████| 55/55 [00:02<00:00, 18.99it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[e=53,   b=1/1]: x = 24.193 y = 27.999, accuracy: 0.8810184879789291, loss: 37.67941740516267\n","[e=54,   b=1/1]: x = 18.204 y = 27.999, accuracy: 0.8331852486347847, loss: 50.25067006971928\n","[e=55,   b=1/1]: x = 20.476 y = 27.999, accuracy: 0.9630387597453476, loss: 25.049187664182792\n","Finished training model: epochs: 55. train time: 2.8994 sec (0.0483 min.). total accuracy: 0.7658, MSE loss: 187.4399. Saved model.\n"],"name":"stdout"}]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"comma-speed-challenge-lowram.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMpb0EntONguwZKB8VWfp6p"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Zy9eetG2PaP4","executionInfo":{"status":"ok","timestamp":1601778440752,"user_tz":240,"elapsed":17490,"user":{"displayName":"e e","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRFShoYRsDhZnpGvDhrdiTr-lcKIMYOM41EgrP=s64","userId":"09974983085928519513"}},"outputId":"4f50fd2a-1aa1-44b6-8f3c-1adfda8a83a0","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","from google.colab import files\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QuD-exHYPz4B"},"source":["def make_optical_flow(data, shuffle):\n","  flow_data_both = []\n","  for i in range(len(data)-1):\n","    img1 = data[i][0]\n","    img2 = data[i+1][0]\n","\n","    brightness_factor = np.random.uniform() + 0.7\n","    img1 = augment_brightness(img1, brightness_factor)\n","    img2 = augment_brightness(img2, brightness_factor)\n","\n","    flow_img = opticalflow(img1, img2)\n","    flow_img = cv2.resize(flow_img, (IMG_SIZE[0], IMG_SIZE[1]), interpolation=cv2.INTER_AREA)\n","    flow_img = flow_img / 127.5 - 1.0\n","\n","    img1_flip = np.flip(img1, 1)\n","    img2_flip = np.flip(img2, 1)\n","    flow_img_flip = opticalflow(img1_flip, img2_flip)\n","    flow_img_flip = cv2.resize(flow_img, (IMG_SIZE[0], IMG_SIZE[1]), interpolation=cv2.INTER_AREA)\n","    flow_img_flip = flow_img / 127.5 - 1.0\n","\n","    speed1 = data[i][1]\n","    speed2 = data[i+1][1]\n","    mean_speed = [np.mean([speed1, speed2])]\n","\n","    flow_data_both.append([flow_img, mean_speed])\n","    flow_data_both.append([flow_img_flip, mean_speed])\n","\n","  if shuffle:\n","    np.random.shuffle(flow_data_both)\n","\n","  return flow_data_both\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2E9MLaqcPg_P","executionInfo":{"status":"ok","timestamp":1601779683987,"user_tz":240,"elapsed":195925,"user":{"displayName":"e e","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRFShoYRsDhZnpGvDhrdiTr-lcKIMYOM41EgrP=s64","userId":"09974983085928519513"}},"outputId":"9291f43a-4160-4450-8927-57963901024d","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["data_path='/content/drive/My Drive/Colab/comma/comma-speed-challenge/data/'\n","root_path='/content/drive/My Drive/Colab'\n","\n","# use training_flow_data and validation_flow_data [img, speed] arrays to make batches for them both (make_batches())\n","# save train/validation batch data as .npy arrays\n","# load these in to feed as input for train() network.\n","\n","def prep_data():\n","  data_file = \"training_small.npy\"\n","  full_data = np.load(data_path+data_file, allow_pickle=True) # small training data file data[0] == img, data[1] = label\n","  flow_data_xy = make_optical_flow(full_data, shuffle=True)\n","\n","  training_flow_data, validation_flow_data = train_val_split(flow_data_xy, val_size=VAL_SIZE)\n","\n","  train_batch_data = list(make_batches(training_flow_data, BATCH_SIZE, shuffle=True))\n","  validation_batch_data = list(make_batches(validation_flow_data, BATCH_SIZE, shuffle=False))\n","\n","  print(f\"Finished loading {len(training_data)} images of training flow data.\")\n","  print(f\"Finished loading {len(validation_data)} images of validation flow data.\")\n","\n","  return training_batch_data, validation_batch_data\n","\n","  # train_batch_data = list(make_batches(training_data, BATCH_SIZE, shuffle=True))\n","  # print(f\"Finished loading {len(train_batch_data)} batches (b={BATCH_SIZE}) of training samples.\")\n","\n","training_batch_data, valiation_batch_data = prep_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training data length: 8000 frames.\n","validation data length:  2000 frames.\n","Finished loading 8000 images of training flow data.\n","Finished loading 2000 images of validation flow data.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WVgnvVEbPjJd","executionInfo":{"status":"error","timestamp":1601778470064,"user_tz":240,"elapsed":6211,"user":{"displayName":"e e","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRFShoYRsDhZnpGvDhrdiTr-lcKIMYOM41EgrP=s64","userId":"09974983085928519513"}},"outputId":"6360b8af-5828-4c5c-c99b-103cd6ee6b08","colab":{"base_uri":"https://localhost:8080/","height":249}},"source":["#!/usr/bin/env python\n","\n","import os\n","import time\n","import torch\n","import torchvision\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision import datasets, transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import copy\n","\n","import cv2\n","import numpy as np\n","import random\n","from random import randint\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","learning_rate = 0.001\n","\n","VAL_SIZE = 0.2\n","EPOCHS = 55\n","BATCH_SIZE = 32\n","INPUT_CHANNELS = 3\n","IMG_SIZE = (200, 66)\n","\n","# tensorboard\n","log_dir = \"./logs\"\n","writer = SummaryWriter(log_dir)\n","\n","def train_val_split(data, val_size):\n","\n","\tval_size = int(len(data) * val_size)\n","\n","\ttraining_data = data[:-val_size]\n","\tvalidation_data = data[-val_size:]\n","\n","\tprint(f\"Training data length: {len(training_data)} frames.\")\n","\tprint(f\"validation data length:  {len(validation_data)} frames.\")\n","\n","\treturn training_data, validation_data\n","\n","def augment_brightness(img, brightness_factor):\n","\t# augment an rgb image with a specified brightness factor, cvt back to rgb and return img as np.array.\n","\thsv_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","\thsv_image[:, :, 2] = hsv_image[:, :, 2] * brightness_factor\n","\timg = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2BGR)\n","\treturn img\n","\n","def opticalflow(img1, img2): # DOF\n","\t\n","\thsv = np.zeros_like(img1)\n","\thsv[...,1] = 255\n","\n","\tgray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n","\tgray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n","\n","\t# flow_data = cv2.calcOpticalFlowFarneback(prev, nxt, None, 0.4, 1, 12, 2, 8, 1.2, 0)\n","\tflow = cv2.calcOpticalFlowFarneback(gray1, gray2, flow=None, pyr_scale=0.5, \n","                                        levels=3, winsize=15, iterations=3, \n","                                        poly_n=5, poly_sigma=1.2, flags=0)\n","\n","\tmag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n","\n","\thsv[:,:,0] = ang*(180/np.pi/2)\n","\thsv[:,:,2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n","\t# hsv[...,2] = (mag * 15).astype(int)\n","\t\n","\trgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n","\n","\t# plt.imshow(rgb)\n","\t# plt.show()\n","\n","\treturn rgb\n","\n","# opticalflow(train_data[0][0], train_data[1][0])\n","\n","def make_batches(data, batch_size, shuffle):\n","\n","\t# data fed into this is sequential and unshuffled video driving data.\n","\t# once flow images are calculated they (can) be shuffled\n","\n","\tx_data = []\n","\ty_data = []\n","\n","\tdata_both = []\n","\n","\tflow_data = []\n","\tspeed_data = []\n","\n","\timg_channels = 3 # img channels for making flow images with cv2 input is 3 to keep hsv.\n","\t\t\t\t\t# INPUT_CHANNELS = 2 -> hsv images are converted to 2-channel np arrays to input for network.\n","\n","\t# generate all dense optical flow images from data images and their associated labels\n","\tfor i in range(0, len(data)-1, 1):\n","\t\t# 2 imgs per step = 32 images for batch=32.\n","\t\timg1 = data[i][0]\n","\t\t# print(i)\n","\t\timg2 = data[i+1][0]\n","\t\t\n","\t\t# preprocessing images to optimize generalization\n","\t\tbrightness_factor = np.random.uniform() + 0.7\n","\t\timg1 = augment_brightness(img1, brightness_factor)\n","\t\timg2 = augment_brightness(img2, brightness_factor)\n","\n","\t\t# plt.imshow(img2)\n","\t\t# plt.show()\n","\n","\t\tflow_img = opticalflow(img1, img2)\n","\t\tflow_img = cv2.resize(flow_img, (IMG_SIZE[0], IMG_SIZE[1]), interpolation=cv2.INTER_AREA)\n","\t\tflow_img = flow_img / 127.5 - 1.0\n","\t\t\n","\t\t# flip image and make another flow image\n","\t\timg1_flip = np.flip(img1, 1)\n","\t\timg2_flip = np.flip(img2, 1)\n","\t\tflow_img_flip = opticalflow(img1_flip, img2_flip)\n","\t\tflow_img_flip = cv2.resize(flow_img_flip, (IMG_SIZE[0], IMG_SIZE[1]), interpolation=cv2.INTER_AREA)\n","\t\tflow_img_flip = flow_img_flip / 127.5 - 1.0\n","\n","\t\tspeed1 = data[i][1]\n","\t\tspeed2 = data[i+1][1]\n","\t\tmean_speed = [np.mean([speed1, speed2])]\n","\n","\t\t# put [flow img, label] in an array, shuffle this array.\n","\t\tdata_both.append([flow_img, mean_speed])\n","\t\tdata_both.append([flow_img_flip, mean_speed])\n","\n","\tif shuffle:\n","\t\trandom.shuffle(data_both)\n","\tfor i in range(len(data_both)):\n","\t\t# make parallel arrays of flow imgs, label.\n","\t\tflow_data.append(data_both[i][0])\n","\t\tspeed_data.append(data_both[i][1])\n","\n","\t# sort all DOF data into batches=32\n","\timage_batch = np.empty((batch_size, IMG_SIZE[1], IMG_SIZE[0], img_channels), dtype=\"float64\")\n","\tlabel_batch = np.empty((batch_size, 1))\n","\n","\tidx = 0\n","\tfor j in range(len(flow_data)):\n","\t\tif idx % batch_size == 0 and idx != 0:\n","\t\t\t# finished a batch\n","\t\t\timg_batch = image_batch\n","\t\t\t# img_batch = img_batch[:,:,:,[0,2]] # extract hue and value channels with flow data\n","\t\t\timg_batch = np.reshape(img_batch, (batch_size, INPUT_CHANNELS, IMG_SIZE[0], IMG_SIZE[1]))\n","\t\t\tx_data.append(copy.deepcopy(torch.from_numpy(img_batch)))\n","\t\t\ty_data.append(copy.deepcopy(torch.DoubleTensor(label_batch)))\n","\t\t\tidx = 0\n","\n","\t\timage_batch[idx] = flow_data[j]\t\t\t# idx loops 0-31, makes batches of 32.\n","\t\tlabel_batch[idx] = speed_data[j]\t\t# j loops len of flow_data\n","\t\tidx += 1\n","\n","\t# x_data = array of 32-batch image tensors, [0] is a batch, [1] is a batch, etc.\n","\t# y_data = array of 32-batch labels\n","\treturn zip(x_data, y_data)\n","\n","class SNet(nn.Module):\n","\tdef __init__(self):\n","\t\tsuper().__init__()\n","\t\tself.conv1 = nn.Conv2d(in_channels=INPUT_CHANNELS, out_channels=24, kernel_size=5, stride=2)\n","\t\tself.conv2 = nn.Conv2d(in_channels=24, out_channels=36, kernel_size=5, stride=2)\n","\t\tself.conv3 = nn.Conv2d(in_channels=36, out_channels=48, kernel_size=5, stride=2)\n","\t\tself.conv3_drop = nn.Dropout2d(p=0.5)\n","\t\tself.conv4 = nn.Conv2d(in_channels=48, out_channels=64, kernel_size=3)\n","\t\tself.conv5 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n","\t\tself.conv_flatten = nn.Flatten()\n","\n","\t\tself.fc1 = nn.Linear(in_features=1152, out_features=100)\n","\t\tself.fc2 = nn.Linear(in_features=100, out_features=50)\n","\t\t# self.fc2_drop = nn.Dropout2d(p=0.5)\n","\t\tself.fc3 = nn.Linear(in_features=50, out_features=10)\n","\t\tself.fc4 = nn.Linear(in_features=10, out_features=1)\n","\n","\t# tests:\n","\t\t# - remove dropout from conv layer\n","\t\t# - decrease parameters in dense layers with dropouts to prevent overfit\n","\t\t# 5 conv layers, 2 dense\n","\n","\t# next to do\n","\t\t# - 5 conv nets, 3 dense nets, \n","\n","\tdef forward(self, x):\n","\t\tx = F.relu(self.conv1(x))\n","\t\tx = F.relu(self.conv2(x))\n","\t\tx = F.relu(self.conv3(x))\n","\t\tx = self.conv3_drop(x)\n","\t\tx = F.relu(self.conv4(x))\n","\t\tx = F.relu(self.conv5(x))\n","\t\tx = self.conv_flatten(x)\n","\n","\t\t# x = x.view(-1, x[0].shape[0]*x[0].shape[1]*x[0].shape[2]) # reshape to 128, in features of first nn.Linear layer.\n","\t\tx = F.relu(self.fc1(x))\n","\t\tx = F.relu(self.fc2(x))\n","\t\t# x = self.fc2_drop(x)\n","\t\tx = F.relu(self.fc3(x)) # no activation function\n","\t\tx = self.fc4(x)\n","\t\treturn x\n","\n","# def prep_data():\n","#   data_file = \"training_full_quarter4.npy\"\n","#   full_data = np.load(data_path+data_file, allow_pickle=True) # small training data file data[0] == img, data[1] = label\n","\n","#   training_data, validation_data = train_val_split(full_data, val_size=VAL_SIZE)\n","\n","#   train_batch_data = list(make_batches(training_data, BATCH_SIZE, shuffle=True))\n","#   print(f\"Finished loading {len(train_batch_data)} batches (b={BATCH_SIZE}) of training samples.\")\n","\n","#   validation_batch_data = list(make_batches(validation_data, BATCH_SIZE, shuffle=False))\n","#   print(f\"Finished loading {len(validation_batch_data)} batches (b={BATCH_SIZE}) of validation samples.\")\n","\n","#   return train_batch_data, validation_batch_data\n","\n","# train_batch_data, validation_batch_data = prep_data()\n","\n","# TRAINING\n","def train_model(train_batch_data, validation_batch_data):\n","\ttrain_start_time = time.time()\n","\n","\ttotal_steps = 0\n","\ttotal_accuracy = 0\n","\ttotal_loss = 0\n","\tval_loss = 0\n","\n","\t# model = torch.load(\"MODEL-(=70e)-DOF-[full].pth\")\n","\tmodel = net\n","\toptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","\tfor epoch in tqdm(range(EPOCHS)):\n","\t\tnum_steps_print = 1\n","\t\tnum_steps_test = 25\n","\t\trunning_loss = 0.0\n","\n","\t\tfor i in tqdm(range(0, len(train_batch_data), 1)): # loop over each batch, begin at 0: i = idx, data = data[img, label]\n","\t\t\ttotal_steps += 1\n","\n","\t\t\tdata = train_batch_data[i]\n","\n","\t\t\tb_imgs, b_labels = data\n","\t\t\tb_imgs, b_labels = b_imgs.to(device), b_labels.to(device)\n","\n","\t\t\toutputs = model(b_imgs)\n","\t\t\t# outputs are ([1, 32]) == labels ([1, 32]) for loss function.\n","\n","\t\t\taccuracy = torch.mean( outputs / b_labels ).item() # every batch\n","\t\t\ttotal_accuracy += torch.mean( outputs / b_labels ).item() # entirety of training\n","\n","\t\t\tloss = loss_function(outputs, b_labels)\n","\t\t\tloss.backward()\n","\t\t\toptimizer.step()\n","\t\t\toptimizer.zero_grad()\n","\t \n","\t\t\trunning_loss += loss.item()\n","\t\t\ttotal_loss += loss.item()\n","\n","\t\t\t# test on validation data\n","\t\t\tif i % num_steps_test == num_steps_test-1:\n","\t\t\t\tidx = randint(0, len(validation_batch_data) - 1)\n","\t\t\t\ttest_x, test_y = validation_batch_data[idx] # [0] == imgs\n","\t\t\t\ttest_x, test_y = test_x.to(device), test_y.to(device)\n","\t\t\t\tval_outputs = model(test_x)\n","\t\t\t\tval_loss = loss_function(val_outputs, test_y).item()\t\n","\t\t\t\tval_accuracy = torch.mean(val_outputs / test_y).item()\n","\n","\t\t\t\t# tensorboard log validation\n","\t\t\t\twriter.add_scalar('Loss/validation', val_loss, (i+1)*(epoch+1))\n","\t\t\t\twriter.add_scalar('Accuracy/validation', val_accuracy, (i+1)*(epoch+1))\n","\t\t\t\tprint(f\"[{epoch + 1}/{EPOCHS},   {i + 1}/{len(train_batch_data)}], [VALIDATION]: x = {round(val_outputs[0].item(), 3)} y = {round(test_y[0].item(), 3)}, accuracy: {val_accuracy}, loss: {val_loss}\")\n","\n","\t\t\tif i % num_steps_print == num_steps_print-1: # print update every 10 steps\n","\t\t\t\tprint(f\"[e={epoch + 1},   b={i + 1}/{len(train_batch_data)}]: x = {round(outputs[0].item(), 3)} y = {round(b_labels[0].item(), 3)}, accuracy: {accuracy}, loss: {running_loss/num_steps_print}\")\n","\t\t\t\twriter.add_scalar('Loss/train', running_loss/num_steps_print, (i+1)*(epoch+1))\n","\t\t\t\twriter.add_scalar('Accuracy/train', accuracy, (i+1)*(epoch+1))\n","\t\t\t\trunning_loss = 0\n","\n","\t# finished epochs\n","\ttrain_time = time.time() - train_start_time\n","\ttorch.save(model, f\"MODEL-(={EPOCHS}e)-DOF-[full].pth\")\n","\t# files.download(f\"MODEL-(={EPOCHS}e)-DOF-[full].pth\")\n","\tprint(f\"Finished training model: epochs: {EPOCHS}. train time: {round(train_time, 4)} sec ({round(train_time/60, 4)} min.). total accuracy: {round((total_accuracy/total_steps),4)}, MSE loss: {round((total_loss/total_steps),4)}. Saved model.\")\n","\n","if __name__ == \"__main__\":\n","\t\n","\tif torch.cuda.is_available():\n","\t\tprint(\"CUDA: True. Running on the GPU.\")\n","\telse:\n","\t\tprint(\"CUDA: False. Slow on the CPU.\")\n","\tdevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","\tnet = SNet().to(device)\n","\tnet = net.double()\n","\tloss_function = nn.MSELoss()\n","\toptimizer = optim.Adam(net.parameters(), lr=learning_rate)\n","\n","\ttrain_model(train_batch_data, validation_batch_data)\n","\t# test_model(video_file=\"data/test.mp4\", model=\"MODEL-(=50e)-DOF-[2chan].pth\")\n","\n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CUDA: False. Slow on the CPU.\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-081343c56636>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_batch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;31m# test_model(video_file=\"data/test.mp4\", model=\"MODEL-(=50e)-DOF-[2chan].pth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_batch_data' is not defined"]}]},{"cell_type":"code","metadata":{"id":"s-VAX8i3Pnca"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]}]}